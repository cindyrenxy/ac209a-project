{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b0505dc",
   "metadata": {},
   "source": [
    "# Supplemental File: Imputation & Feature Selection\n",
    "\n",
    "This notebook contains all trials and benchmarking work on finding the optimal imputation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51b0e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.experimental import enable_iterative_imputer  \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import f1_score\n",
    "from itertools import product\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44a2282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/training_v2.csv\") # load the dataset\n",
    "df_test = pd.read_csv(\"data/unlabeled.csv\") # load the unlabeled test set\n",
    "\n",
    "# specify response variable\n",
    "target = \"hospital_death\"\n",
    "y = df[target]\n",
    "X = df.drop(columns=[target])\n",
    "X_unlabeled = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b183ef",
   "metadata": {},
   "source": [
    "## 1. Feature Selection\n",
    "\n",
    "In this section, we explored feature selection strategies to improve model stability, reduce noise, and streamline the downstream predictive workflow. Numerical, binary, and categorical features were examined separately to ensure that each variable was handled appropriately according to its data type. Initial screening included correlation checks, missingness assessment, and variance filtering to detect redundancy and identify features likely to contribute predictive value.\n",
    "\n",
    "Although feature selection was later moved to occur post-imputation in the final pipeline, an initial round of preprocessing was still applied before imputation to remove features that were clearly uninformative or unsuitable for modeling. Specifically, we dropped identifier-like columns (`encounter_id`, `hospital_id`, `patient_id`, `icu_id`) as they carry no predictive signal, and removed numerical variables with more than 80% missingness or zero variance, as these would be difficult to impute and unlikely to add meaningful information. In total, 39 columns were removed during this initial filtering process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05180542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features filtered out (missing > 80% or SD=0): 35\n"
     ]
    }
   ],
   "source": [
    "# remove identifier columns\n",
    "id_cols = ['encounter_id', 'hospital_id', 'patient_id', 'icu_id']\n",
    "df.drop(columns=id_cols, inplace=True) # drop identifier columns\n",
    "\n",
    "# identify numerical and categorical columns\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "bin_cols = [col for col in num_cols if df[col].nunique() == 2]\n",
    "num_cols = num_cols.drop(bin_cols)\n",
    "cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "\n",
    "# identify columns with >80% missing values\n",
    "missing_rate = df[num_cols].isnull().mean()\n",
    "high_missing_cols = missing_rate[missing_rate > 0.8].index.tolist()\n",
    "\n",
    "# identify columns with zero standard deviation\n",
    "df_temp = df[num_cols].fillna(df[num_cols].mean())\n",
    "zero_std_cols = df_temp.columns[df_temp.std() == 0].tolist()\n",
    "\n",
    "# remove highly missing and zero std columns from numerical features\n",
    "filtered_numeric_cols = [c for c in num_cols if c not in high_missing_cols + zero_std_cols]\n",
    "print(f\"Features filtered out (missing > 80% or SD=0): {len(high_missing_cols) + len(zero_std_cols)}\")\n",
    "num_cols = filtered_numeric_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5154d6e8",
   "metadata": {},
   "source": [
    "## 2. Imputation\n",
    "\n",
    "To evaluate imputation strategies for our dataset, we generated a ground-truth reference by imputing missing values and scaling continuous variables, then simulated missingness under a MCAR mechanism using randomized masking. We compared four imputation approaches applied only to continuous features - Mean, Median, KNN, and MICE - while binary and categorical variables were imputed consistently using most-frequent substitution for fairness. This is likely because many binary variables classified as MAR represent unlabeled or clinically insignificant results. Each method was wrapped inside a CompositeImputer class and assessed through 3-fold cross-validation, ensuring robustness against sampling variance.\n",
    "\n",
    "Model performance was evaluated using RMSE measured only on artificially missing values to prevent information leakage. MICE achieved the lowest error across continuous variables (~0.61 RMSE) followed by KNN (~0.86 RMSE), whereas mean and median imputers performed similarly but worse overall (~0.98â€“1.00 RMSE). Binary columns showed identical RMSE across methods as expected, confirming that benchmarking primarily reflects numeric imputation quality. These results are consistent with literature: model-based imputers such as MICE generally outperform simpler univariate imputers when variables show correlation structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2f5e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_mask(df_nona, missing_rate=0.2, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    mask = pd.DataFrame(\n",
    "        rng.random(df_nona.shape) < missing_rate,\n",
    "        index=df_nona.index,\n",
    "        columns=df_nona.columns)\n",
    "    return mask\n",
    "\n",
    "def impute(df_masked, num_cols, cat_cols, num_method, cat_method):\n",
    "    df_imputed = df_masked.copy()\n",
    "    # impute numerical columns\n",
    "    num_vals = num_method.fit_transform(df_imputed[num_cols])\n",
    "    df_imputed[num_cols] = num_vals\n",
    "\n",
    "    # inpute categorical columns\n",
    "    cat_vals = cat_method.fit_transform(df_imputed[cat_cols])\n",
    "    df_imputed[cat_cols] = np.array(cat_vals).reshape(-1, len(cat_cols))\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "# evaluate performance of \n",
    "def evaluate_imputation(df_nona, df_imputed, mask, num_cols, cat_cols):\n",
    "    # evaluate numerical cols imputations using RMSE\n",
    "    all_num = df_nona[num_cols]\n",
    "    imp_num = df_imputed[num_cols]\n",
    "    specific_num_mask = mask[num_cols]\n",
    "\n",
    "    # extract only the values where the mask is True (the imputed positions)\n",
    "    true_num_values = all_num.values[specific_num_mask.values]\n",
    "    imp_num_values = imp_num.values[specific_num_mask.values]\n",
    "\n",
    "    # calculate RMSE\n",
    "    if len(true_num_values) > 0:\n",
    "        rmse = np.sqrt(mean_squared_error(true_num_values, imp_num_values))\n",
    "    else:\n",
    "        rmse = 0 # handle case where no values were imputed\n",
    "\n",
    "    # evaluate categorical cols imputations using accuracy\n",
    "    cat_cols_to_evaluate = df_nona[cat_cols]\n",
    "    imp_cat_cols = df_imputed[cat_cols]\n",
    "    specific_cat_mask = mask[cat_cols]\n",
    "\n",
    "    true_cat_values = cat_cols_to_evaluate.values[specific_cat_mask.values]\n",
    "    imp_cat_values = imp_cat_cols.values[specific_cat_mask.values]\n",
    "\n",
    "    if len(true_cat_values) > 0:\n",
    "        acc = (true_cat_values == imp_cat_values).mean()\n",
    "    else:\n",
    "        acc = 1.0 # Or 0, depending on context\n",
    "    \n",
    "    f1_macro = f1_score(true_cat_values, imp_cat_values, average=\"macro\")\n",
    "\n",
    "    return rmse, acc, f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c997a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create scaled ground truth dataset\n",
    "# ---------------------------------------------------------\n",
    "all_cols = list(num_cols) + list(bin_cols) + list(cat_cols)\n",
    "X_full = df[all_cols].copy()\n",
    "\n",
    "# 1a. fill NaNs to create \"Truth\" set\n",
    "X_full[bin_cols] = SimpleImputer(strategy='most_frequent').fit_transform(X_full[bin_cols])\n",
    "X_full[num_cols] = SimpleImputer(strategy='mean').fit_transform(X_full[num_cols])\n",
    "X_full[cat_cols] = SimpleImputer(strategy='most_frequent').fit_transform(X_full[cat_cols])\n",
    "\n",
    "# 1b. scale num_cols for KNN/MICE\n",
    "scaler = StandardScaler()\n",
    "X_full[num_cols] = scaler.fit_transform(X_full[num_cols])\n",
    "\n",
    "# use a manageable sample size for the heavy CV benchmarking\n",
    "X_ground_truth = X_full.sample(n=3000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21a1c802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Specify imputers for categorical, binary, and continuous data\n",
    "# ---------------------------------------------------------\n",
    "# Imputer for Fixed Binary/Categorical Strategy (Mode)\n",
    "class FixedModeImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.imputer_ = SimpleImputer(strategy='most_frequent').fit(X)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return self.imputer_.transform(X)\n",
    "\n",
    "# Orchestrator Class: Combines Fixed Binary/Cat Imputation with the Benchmarked Numeric Method\n",
    "class CompositeImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cont_imputer, numeric_cols, binary_cols, categorical_cols):\n",
    "        self.num_cols = numeric_cols\n",
    "        self.bin_cols = binary_cols\n",
    "        self.cat_cols = categorical_cols\n",
    "        \n",
    "        # Benchmarked Imputer for Continuous (num_cols)\n",
    "        self.cont_imputer = cont_imputer \n",
    "        \n",
    "        # Fixed Imputer for Binary (bin_cols) and Categorical (cat_cols)\n",
    "        self.bin_imputer = SimpleImputer(strategy='most_frequent', add_indicator=False)\n",
    "        self.cat_imputer = SimpleImputer(strategy='most_frequent', add_indicator=False)\n",
    "        self.feature_names_in_ = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_names_in_ = X.columns.tolist()\n",
    "        \n",
    "        # Fit Continuous (num_cols)\n",
    "        self.cont_imputer.fit(X[self.num_cols])\n",
    "        \n",
    "        # Fit Fixed strategies\n",
    "        self.bin_imputer.fit(X[self.bin_cols])\n",
    "        self.cat_imputer.fit(X[self.cat_cols])\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        # 1. Continuous (num_cols) -> Benchmarked Imputer (e.g., KNN/MICE)\n",
    "        df_num = pd.DataFrame(self.cont_imputer.transform(X[self.num_cols]), \n",
    "                              columns=self.num_cols, index=X.index)\n",
    "        \n",
    "        # 2. Binary (bin_cols) -> Fixed Mode Imputation\n",
    "        df_bin = pd.DataFrame(self.bin_imputer.transform(X[self.bin_cols]),\n",
    "                              columns=self.bin_cols, index=X.index)\n",
    "        \n",
    "        # 3. Categorical (cat_cols) -> Fixed Mode Imputation\n",
    "        df_cat = pd.DataFrame(self.cat_imputer.transform(X[self.cat_cols]),\n",
    "                              columns=self.cat_cols, index=X.index)\n",
    "        \n",
    "        # Recombine and return in original order\n",
    "        return pd.concat([df_num, df_bin, df_cat], axis=1)[self.feature_names_in_].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c93575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 3-Fold CV Benchmark on 3000 rows...\n"
     ]
    }
   ],
   "source": [
    "# 3. Define Imputers to Benchmark\n",
    "# ---------------------------------------------------------\n",
    "# We only benchmark the Continuous Imputer part, wrapping them in the Composite strategy\n",
    "def create_composite(imputer_name):\n",
    "    if imputer_name == \"KNN\":\n",
    "        return CompositeImputer(KNNImputer(n_neighbors=5), num_cols, bin_cols, cat_cols)\n",
    "    if imputer_name == \"MICE\":\n",
    "        return CompositeImputer(IterativeImputer(max_iter=50, random_state=42), num_cols, bin_cols, cat_cols)\n",
    "    if imputer_name == \"Mean\":\n",
    "        return CompositeImputer(SimpleImputer(strategy='mean'), num_cols, bin_cols, cat_cols)\n",
    "    if imputer_name == \"Median\":\n",
    "        return CompositeImputer(SimpleImputer(strategy='median'), num_cols, bin_cols, cat_cols)\n",
    "    return None\n",
    "\n",
    "imputers_to_run = {\n",
    "    \"Composite_Mean\": create_composite(\"Mean\"),\n",
    "    \"Composite_Median\": create_composite(\"Median\"),\n",
    "    \"Composite_KNN\": create_composite(\"KNN\"),\n",
    "    \"Composite_MICE\": create_composite(\"MICE\"),\n",
    "}\n",
    "\n",
    "# 4. Cross-Validated Benchmarking Function\n",
    "# ---------------------------------------------------------\n",
    "def benchmark_cv(X_true, imputers_dict, n_splits=3, missing_rate=0.2):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    results = []\n",
    "    \n",
    "    print(f\"Running {n_splits}-Fold CV Benchmark on {len(X_true)} rows...\")\n",
    "    \n",
    "    for fold, (_, test_idx) in enumerate(kf.split(X_true), 1):\n",
    "        X_fold = X_true.iloc[test_idx].copy()\n",
    "        \n",
    "        # Generate Random Mask (MCAR Simulation)\n",
    "        rng = np.random.default_rng(fold)\n",
    "        mask = pd.DataFrame(rng.random(X_fold.shape) < missing_rate, index=X_fold.index, columns=X_fold.columns)\n",
    "        X_masked = X_fold.mask(mask)\n",
    "        \n",
    "        for name, imputer in imputers_dict.items():\n",
    "            imputer.fit(X_masked)\n",
    "            X_imp_df = pd.DataFrame(imputer.transform(X_masked), columns=X_masked.columns, index=X_masked.index)\n",
    "            \n",
    "            # Calculate RMSE only on the imputed numerical columns\n",
    "            def calc_rmse(cols):\n",
    "                if len(cols) == 0: return 0.0\n",
    "                m = mask[cols].values\n",
    "                if m.sum() == 0: return 0.0\n",
    "                return np.sqrt(mean_squared_error(X_fold[cols].values[m], X_imp_df[cols].values[m]))\n",
    "            \n",
    "            results.append({\n",
    "                \"Method\": name,\n",
    "                \"Fold\": fold,\n",
    "                \"RMSE_Total_Num\": calc_rmse(num_cols + bin_cols), # Total Numerical RMSE\n",
    "                \"RMSE_Num\": calc_rmse(num_cols),                   # Continuous RMSE (Primary Benchmark)\n",
    "                \"RMSE_Bin\": calc_rmse(bin_cols)                    # Binary RMSE (Fixed Strategy Check)\n",
    "            })\n",
    "        \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 5. Execute and Report\n",
    "# ---------------------------------------------------------\n",
    "df_results = benchmark_cv(X_ground_truth, imputers_to_run, n_splits=3)\n",
    "summary = df_results.groupby(\"Method\")[[\"RMSE_Total_Num\", \"RMSE_Num\", \"RMSE_Bin\"]].agg(['mean', 'std'])\n",
    "\n",
    "print(\"\\nImputation Benchmark Results (Mean RMSE +/- Std Dev):\")\n",
    "print(\"Note: Continuous (num_cols) data is Z-score scaled.\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1475c02c",
   "metadata": {},
   "source": [
    "## 3. Summary\n",
    "Overall, the imputation experiment demonstrates that MICE offers the most accurate recovery of continuous values, producing the lowest RMSE in every evaluation fold. Given this performance advantage and the presence of correlated features in the dataset,** MICE is selected as the default imputation strategy** moving forward. Mean/Median imputers remain useful as lightweight baselines and sensitivity comparisons, while KNN serves as a reasonable alternative balancing performance and computational cost. Future extensions may consider MAR/MNAR simulations or downstream model evaluation after imputation to assess whether reduced RMSE also translates into predictive improvement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
